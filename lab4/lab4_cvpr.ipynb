{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"lab4_cvpr.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"P7WLskgPfxqL","executionInfo":{"status":"ok","timestamp":1607350583710,"user_tz":-120,"elapsed":181382,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"8044f3b2-de96-43ae-ccdc-46a75ca448b7"},"source":["!pip install git+https://github.com/facebookresearch/fvcore.git\n","!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n","!pip install -e detectron2_repo\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n","Requirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n","Collecting git+https://github.com/facebookresearch/fvcore.git\n","  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-s1964pmn\n","  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-s1964pmn\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.18.5)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 26.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (4.41.1)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (7.0.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (0.8.7)\n","Building wheels for collected packages: fvcore, pyyaml\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.2-cp36-none-any.whl size=48498 sha256=78841a160cf50fcf44190f146dd3e0fd9c8f8c5fabed1073a65816a602605132\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9kfc9eq6/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=e1acba20864475a202e4ca3218bb772540a431ec0d799fc5b834a07e5ee03ba2\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built fvcore pyyaml\n","Installing collected packages: pyyaml, yacs, portalocker, fvcore\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed fvcore-0.1.2 portalocker-2.0.0 pyyaml-5.3.1 yacs-0.1.8\n","Cloning into 'detectron2_repo'...\n","remote: Enumerating objects: 9142, done.\u001b[K\n","remote: Total 9142 (delta 0), reused 0 (delta 0), pack-reused 9142\u001b[K\n","Receiving objects: 100% (9142/9142), 3.70 MiB | 24.45 MiB/s, done.\n","Resolving deltas: 100% (6689/6689), done.\n","Obtaining file:///content/detectron2_repo\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.1.0)\n","Collecting Pillow>=7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 11.2MB/s \n","\u001b[?25hRequirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.1.8)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.8.7)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (3.2.2)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (4.41.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (2.3.0)\n","Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.1.2)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (2.0.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.16.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.3.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.3) (5.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (0.10.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (1.18.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (1.3.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.35.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (50.3.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.4.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.7.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.10.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.15.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.33.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (3.3.3)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (3.12.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (2.23.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2==0.3) (2.0.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2==0.3) (0.29.21)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (4.1.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.3) (2.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.3) (3.4.0)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: Pillow, detectron2\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Running setup.py develop for detectron2\n","Successfully installed Pillow-8.0.1 detectron2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LL0bGcn-w28","executionInfo":{"status":"ok","timestamp":1607350597003,"user_tz":-120,"elapsed":802,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"c092ab1d-0a42-47e6-895d-2279adbbf2b4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4wtb3KPkLJ-L"},"source":["from detectron2.data.datasets import register_coco_instances"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqW6hQi5it3k"},"source":["register_coco_instances(\"matches\", {}, \"/content/drive/MyDrive/trainval.json\", \"/content/drive/MyDrive/lab4_photos\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLg3q0CDjlZl"},"source":["from detectron2.data import MetadataCatalog,DatasetCatalog\n","MetadataCatalog.get(\"matches\").thing_classes = [\"matches\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxD4W_pGjude"},"source":["disc_metadata = MetadataCatalog.get(\"matches\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"id":"ohxfKsHEpHL5","executionInfo":{"status":"error","timestamp":1607370979079,"user_tz":-120,"elapsed":1191,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"836fa151-ef14-4390-df44-dae3daecb5e7"},"source":["disc_metadata"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a2f3010adef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisc_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'disc_metadata' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKuRzvMUki5X","executionInfo":{"status":"ok","timestamp":1607350645875,"user_tz":-120,"elapsed":1379,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"7b1d9578-a381-499b-ac7c-761129db2575"},"source":["dataset_dicts = DatasetCatalog.get(\"matches\")\n","import random\n","from detectron2.utils.visualizer import Visualizer\n","import cv2\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"D8aaJ6p_kz4z"},"source":["from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","import os\n","cfg = get_cfg()\n","cfg.merge_from_file(\n","    \"/content/detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",")\n","cfg.DATASETS.TRAIN = (\"matches\",)\n","cfg.DATASETS.TEST = () \n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","cfg.SOLVER.BASE_LR = 0.02\n","cfg.SOLVER.MAX_ITER = (\n","    300\n",") \n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (\n","    128\n",")\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Typa8wutY7FQ"},"source":["cfg.OUTPUT_DIR = '/content/drive/MyDrive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XrfR07kgYoFu"},"source":["os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"odWoD4PTZQZh","executionInfo":{"status":"ok","timestamp":1607349592657,"user_tz":-120,"elapsed":832405,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"fd71e8f1-7306-4141-8f75-621aa393eadb"},"source":["trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[12/07 13:46:03 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/07 13:46:03 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[12/07 13:46:03 d2.data.datasets.coco]: \u001b[0mLoaded 97 images in COCO format from /content/drive/MyDrive/trainval.json\n","\u001b[32m[12/07 13:46:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 97 images left.\n","\u001b[32m[12/07 13:46:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[12/07 13:46:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[12/07 13:46:03 d2.data.common]: \u001b[0mSerializing 97 elements to byte tensors and concatenating them all ...\n","\u001b[32m[12/07 13:46:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n"],"name":"stdout"},{"output_type":"stream","text":["Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[32m[12/07 13:46:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","\u001b[32m[12/07 13:46:59 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 19  total_loss: 1.781  loss_cls: 0.6861  loss_box_reg: 0.4874  loss_mask: 0.5782  loss_rpn_cls: 0.004715  loss_rpn_loc: 0.002104  time: 2.6945  data_time: 1.0776  lr: 0.00039962  max_mem: 4654M\n","\u001b[32m[12/07 13:47:54 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 39  total_loss: 0.7934  loss_cls: 0.09592  loss_box_reg: 0.4444  loss_mask: 0.1924  loss_rpn_cls: 0.005402  loss_rpn_loc: 0.002352  time: 2.7250  data_time: 0.8840  lr: 0.00079922  max_mem: 4654M\n","\u001b[32m[12/07 13:48:50 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 59  total_loss: 0.4148  loss_cls: 0.03194  loss_box_reg: 0.2461  loss_mask: 0.1106  loss_rpn_cls: 0.0009317  loss_rpn_loc: 0.003419  time: 2.7517  data_time: 0.9227  lr: 0.0011988  max_mem: 4654M\n","\u001b[32m[12/07 13:49:45 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 79  total_loss: 0.3684  loss_cls: 0.03087  loss_box_reg: 0.2067  loss_mask: 0.1113  loss_rpn_cls: 0.001158  loss_rpn_loc: 0.002351  time: 2.7557  data_time: 0.7627  lr: 0.0015984  max_mem: 4654M\n","\u001b[32m[12/07 13:50:40 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 99  total_loss: 0.2717  loss_cls: 0.032  loss_box_reg: 0.1504  loss_mask: 0.0882  loss_rpn_cls: 0.0004657  loss_rpn_loc: 0.001914  time: 2.7564  data_time: 0.9465  lr: 0.001998  max_mem: 4654M\n","\u001b[32m[12/07 13:51:39 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 119  total_loss: 0.2889  loss_cls: 0.03284  loss_box_reg: 0.1667  loss_mask: 0.08532  loss_rpn_cls: 0.0004479  loss_rpn_loc: 0.00185  time: 2.7858  data_time: 1.0313  lr: 0.0023976  max_mem: 4654M\n","\u001b[32m[12/07 13:52:34 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 139  total_loss: 0.2752  loss_cls: 0.03114  loss_box_reg: 0.1584  loss_mask: 0.07803  loss_rpn_cls: 7.171e-05  loss_rpn_loc: 0.001808  time: 2.7778  data_time: 0.8298  lr: 0.0027972  max_mem: 4654M\n","\u001b[32m[12/07 13:53:29 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 159  total_loss: 0.2597  loss_cls: 0.03267  loss_box_reg: 0.1395  loss_mask: 0.07959  loss_rpn_cls: 0.0002531  loss_rpn_loc: 0.00148  time: 2.7728  data_time: 0.8602  lr: 0.0031968  max_mem: 4654M\n","\u001b[32m[12/07 13:54:22 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 179  total_loss: 0.2428  loss_cls: 0.02724  loss_box_reg: 0.1191  loss_mask: 0.08124  loss_rpn_cls: 0.000153  loss_rpn_loc: 0.001755  time: 2.7599  data_time: 0.9825  lr: 0.0035964  max_mem: 4654M\n","\u001b[32m[12/07 13:55:18 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 199  total_loss: 0.2263  loss_cls: 0.02709  loss_box_reg: 0.1307  loss_mask: 0.07309  loss_rpn_cls: 0.0001398  loss_rpn_loc: 0.001562  time: 2.7648  data_time: 0.9061  lr: 0.003996  max_mem: 4654M\n","\u001b[32m[12/07 13:56:13 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 219  total_loss: 0.2575  loss_cls: 0.02734  loss_box_reg: 0.1464  loss_mask: 0.06812  loss_rpn_cls: 0.0001654  loss_rpn_loc: 0.001775  time: 2.7618  data_time: 0.8679  lr: 0.0043956  max_mem: 4654M\n","\u001b[32m[12/07 13:57:09 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 239  total_loss: 0.2405  loss_cls: 0.02695  loss_box_reg: 0.1453  loss_mask: 0.06795  loss_rpn_cls: 0.0001044  loss_rpn_loc: 0.001634  time: 2.7646  data_time: 0.9021  lr: 0.0047952  max_mem: 4654M\n","\u001b[32m[12/07 13:58:02 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 259  total_loss: 0.2214  loss_cls: 0.02543  loss_box_reg: 0.1316  loss_mask: 0.06171  loss_rpn_cls: 0.0001812  loss_rpn_loc: 0.001602  time: 2.7587  data_time: 0.8074  lr: 0.0051948  max_mem: 4654M\n","\u001b[32m[12/07 13:58:55 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 279  total_loss: 0.2194  loss_cls: 0.02564  loss_box_reg: 0.133  loss_mask: 0.06632  loss_rpn_cls: 0.0002353  loss_rpn_loc: 0.001683  time: 2.7506  data_time: 0.8481  lr: 0.0055944  max_mem: 4654M\n","\u001b[32m[12/07 13:59:53 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.2189  loss_cls: 0.02396  loss_box_reg: 0.1273  loss_mask: 0.07059  loss_rpn_cls: 0.0001574  loss_rpn_loc: 0.001521  time: 2.7516  data_time: 0.8261  lr: 0.005994  max_mem: 4654M\n","\u001b[32m[12/07 13:59:53 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:13:39 (2.7516 s / it)\n","\u001b[32m[12/07 13:59:53 d2.engine.hooks]: \u001b[0mTotal training time: 0:13:42 (0:00:03 on hooks)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CutSb2Wkp7zW"},"source":["from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9HAWFNfildQh"},"source":["cfg.MODEL.WEIGHTS = '/content/drive/MyDrive/model_final.pth'\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\n","cfg.DATASETS.TEST = (\"matches\", )\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-rLXpVFgpQp"},"source":["from skimage.transform import ProjectiveTransform\n","from skimage.io import imread\n","import numpy as np\n","import matplotlib.pylab as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wY_GYQJtiuG5","executionInfo":{"status":"ok","timestamp":1607350800220,"user_tz":-120,"elapsed":886,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"edca3c2d-e408-41c7-8e36-1f4b21d31541"},"source":["print(cfg.MODEL.WEIGHTS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/model_final.pth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vtb_b9TOow_M","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FHXy4IjsrgtQMJEnKxA5A-wqzd52KBXd"},"executionInfo":{"status":"ok","timestamp":1607350824054,"user_tz":-120,"elapsed":19394,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"4d9ec060-5a24-4a0b-9f9f-0a48f7acc390"},"source":["from detectron2.utils.visualizer import ColorMode\n","import random\n","from detectron2.utils.visualizer import Visualizer\n","import cv2\n","from google.colab.patches import cv2_imshow\n","for d in random.sample(dataset_dicts, 1):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    boxes=next(iter(outputs['instances'].pred_boxes)).cpu().numpy()\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=disc_metadata, \n","                   scale=1, \n","                   instance_mode=ColorMode.IMAGE_BW \n","    )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(v.get_image()[:, :, ::-1])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"hkszjKTK4r9R"},"source":["from skimage.transform import ProjectiveTransform\n","from skimage.io import imread\n","import numpy as np\n","import matplotlib.pylab as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISmfJrJRSweC"},"source":["from pylab import rcParams\n","rcParams['figure.figsize'] = 20, 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"inPaTyCTM24k","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1607371983961,"user_tz":-120,"elapsed":858,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"f72a8484-705a-4aa3-f3a7-6dff088e19a2"},"source":["capture = cv2.VideoCapture(\"/content/drive/MyDrive/my_matches_video2.mp4\")\n","fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n","fps = 30\n","w, h = 800, 800\n","stream = cv2.VideoWriter(\"/content/drive/MyDrive/matches_result.avi\", fourcc, fps, (w, h))\n","\n","inplant=cv2.imread(\"/content/drive/MyDrive/target.jpg\")\n","while capture.isOpened():\n","    ret, frame = capture.read()\n","    if ret == False:\n","        break\n","    frame=cv2.resize(frame, (800,800), interpolation = cv2.INTER_AREA)\n","    try:\n","        outputs = predictor(frame)\n","        gray=outputs['instances'].pred_masks.cpu().numpy()[0].astype(np.uint8)*255\n","        _, thresh = cv2.threshold(gray,127,255,0)\n","        contours,hierarchy = cv2.findContours(thresh,1, 2)\n","        cnt = contours[0]\n","        epsilon = 0.1*cv2.arcLength(cnt,True)\n","        approx = cv2.approxPolyDP(cnt,epsilon,True)\n","        box = np.int0(approx)\n","        frameClone = frame.copy()\n","        pts_frame = box.reshape(4,2)\n","        pts_inplant = np.array([[0, 0], [inplant.shape[1] - 1, 0], [inplant.shape[1] - 1, inplant.shape[0] - 1], [0, inplant.shape[0] - 1]])\n","        print(\"Matches\")\n","        homographyMat, status = cv2.findHomography(pts_inplant, pts_frame, cv2.RANSAC,5.0)\n","        result1 = cv2.warpPerspective(inplant, homographyMat, (frame.shape[1], frame.shape[0]))\n","        cv2.fillConvexPoly(frameClone, pts_frame, 0, 16)\n","        frame = frameClone + result1\n","    except:\n","      a=0\n","    stream.write(frame)\n","    if cv2.waitKey(25) == ord('q'):\n","        break\n","    \n","capture.release()\n","stream.release()\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-cb7f4ad2624f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcapture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/my_matches_video2.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfourcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoWriter_fourcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m'DIVX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/matches_result.avi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfourcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":838,"output_embedded_package_id":"1mAObhcoXDSBolcaQx1S0Vc-TwC9kSGJs"},"id":"8Hphz489BKOX","executionInfo":{"status":"ok","timestamp":1607353698362,"user_tz":-120,"elapsed":16591,"user":{"displayName":"Violent_ island","photoUrl":"","userId":"07878924812855683714"}},"outputId":"43ca24a7-2129-465d-d193-ff0d6678ac15"},"source":["from moviepy.editor import *\n","\n","path=\"/content/drive/MyDrive/matches_result.avi\" \n","\n","clip=VideoFileClip(path)\n","clip.ipython_display(width=800)\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"7RUvrTwDTQvy"},"source":[""],"execution_count":null,"outputs":[]}]}